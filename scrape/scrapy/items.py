from datetime import datetime
from scrapy.item import Field, Item, ItemMeta
from scrapy.contrib.loader import ItemLoader, XPathItemLoader
import django.db.models as django_models
from processors import *


class DjangoItemMeta(ItemMeta):

    def  __new__(mcs, class_name, bases, attrs):

        # Use this function to pick an appropriate input processor.
        def select_input_processor(field):
            if isinstance(field, django_models.FloatField):
                return Float()
            elif isinstance(field, django_models.IntegerField):
                return Int()
            elif isinstance(field, django_models.BooleanField):
                return Bool()
            elif isinstance(field, django_models.DateTimeField):
                return DateTime()
            elif isinstance(field, django_models.DateField):
                return Date()
            else:
                return MapCompose(RemoveEntities(), Strip())

        # Instantiate our class from the parent and copy their fields.
        cls = super(DjangoItemMeta, mcs).__new__(mcs, class_name, bases, attrs)
        cls.fields = cls.fields.copy()

        # If no Django model was given just use a normal item.
        django_model = cls.django_model
        if not django_model:
            return cls

        # Are we using a ScrapeModel?
        scrape_model = False
        try:
            from gigspot_site.scrape.models import ScrapeModel
            if isinstance(django_model, type(ScrapeModel)):
                scrape_model = True
        except:
            pass

        # If we were flagged as using a ScrapeModel, hunt down the actual target.
        if scrape_model:
            cls._scrape_model = django_model
            target = django_model._meta.get_field_by_name('target')[0]
            django_model = target.rel.to

        cls._model_fields = []
        cls._model_meta = django_model._meta

        # First create the normal fields.
        for model_field in cls._model_meta.fields:
            # XXX: for now we're treating each PK as autogenerated field
            if model_field.name != 'id':

                # If we don't already have a field defined, create a new one.
                if model_field.name not in cls.fields:

                    # Select an appropriate input and output processor.
                    cls.fields[model_field.name] = Field(
                        input_processor=select_input_processor(model_field),
                        output_processor=TakeFirst()
                    )
                cls._model_fields.append(model_field.name)

                # If we have a scrape model, add the extra fields.
                if scrape_model:
                    cls.fields[model_field.name + '_source'] = Field()
                    cls.fields[model_field.name + '_timestamp'] = Field(input_processor=DateTime())

        # Now handle many-to-many fields.
        for model_field in cls._model_meta.many_to_many:
            if model_field.name not in cls.fields:
                cls.fields[model_field.name] = Field(
                    input_processor=select_input_processor(model_field)
                )
            cls._model_fields.append(model_field.name)

            # If we have a scrape model, add the extra fields.
            if scrape_model:
                cls.fields[model_field.name + '_source'] = Field()
                cls.fields[model_field.name + '_timestamp'] = Field(input_processor=DateTime())

        return cls


class DjangoItem(Item):
    __metaclass__ = DjangoItemMeta
    django_model = None

    # We use the "id" field to form links between models for related fields.
    id = Field(input_processor=MapCompose(RemoveEntities(), Strip()), output_processor=TakeFirst())
    scrape_url = Field(output_processor=TakeFirst())
    scrape_datetime = Field(input_processor=DateTime(), output_processor=TakeFirst())
    valid = Field(default=False)

    def save(self):
        pass


class DjangoItemLoader(ItemLoader):

    def __init__(self, item, response, id=None, **kwargs):
        ItemLoader.__init__(self, item, **kwargs)
        self._source = str(response.url)
        if id is not None:
            self.add_value('id', id)

    def add_value(self, field_name, value, *args, **kwargs):
        return self._wrapper(field_name, value, 'add_value', *args, **kwargs)

    def replace_value(self, field_name, value, *args, **kwargs):
        return self._wrapper(field_name, value, 'replace_value', *args, **kwargs)

    def _wrapper(self, field_name, value, call, *args, **kwargs):
        parent = super(DjangoItemLoader, self)

        # If we using our special ScrapeModel class, add in the extra bits.
        if hasattr(self.item, '_scrape_model') and field_name != 'id':
            parent.replace_value(field_name + '_source', self._source)
            parent.replace_value(field_name + '_timestamp', datetime.now())

        return getattr(parent, call)(field_name, value, *args, **kwargs)


class DjangoXPathItemLoader(XPathItemLoader):

    def __init__(self, item, response, id, selector=None, **context):
        XPathItemLoader.__init__(self, item, selector, response, **context)
        self._source = str(response.url)
        if id is not None:
            self.add_value('id', id)

    def add_value(self, field_name, value, *args, **kwargs):
        return self._wrapper(field_name, value, 'add_value', *args, **kwargs)

    def replace_value(self, field_name, value, *args, **kwargs):
        return self._wrapper(field_name, value, 'replace_value', *args, **kwargs)

    def _wrapper(self, field_name, value, call, *args, **kwargs):
        parent = super(DjangoXPathItemLoader, self)

        # If we using our special ScrapeModel class, add in the extra bits.
        if hasattr(self.item, '_scrape_model') and field_name != 'id':
            parent.replace_value(field_name + '_source', self._source)
            parent.replace_value(field_name + '_timestamp', datetime.now())

        return getattr(parent, call)(field_name, value, *args, **kwargs)
